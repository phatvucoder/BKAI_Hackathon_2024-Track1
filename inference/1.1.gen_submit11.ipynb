{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleted old predictions\n",
    "!rm -rf predict.txt predict.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [06:05<00:00,  7.04s/it]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Đọc danh sách tệp ảnh\n",
    "data_test = sorted(glob.glob(\"../data/raw/private test/*.jpg\"))\n",
    "batch_size = 64  # Đặt số lượng ảnh trong mỗi batch, điều chỉnh sao cho phù hợp với RAM của bạn\n",
    "\n",
    "# Tạo model\n",
    "model = YOLO(\"../models/base2/base/base.pt\")\n",
    "\n",
    "# Hàm chuyển đổi tọa độ từ xyxy sang xywh\n",
    "def xyxy_to_xywh(xyxy, img_width, img_height):\n",
    "    xmin, ymin, xmax, ymax = xyxy\n",
    "    x_center = (xmin + xmax) / 2 / img_width\n",
    "    y_center = (ymin + ymax) / 2 / img_height\n",
    "    width = (xmax - xmin) / img_width\n",
    "    height = (ymax - ymin) / img_height\n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "# Xử lý theo batch và ghi kết quả\n",
    "with open(\"predict.txt\", \"w\") as f:\n",
    "    for i in tqdm(range(0, len(data_test), batch_size)):\n",
    "        batch_files = data_test[i:i + batch_size]\n",
    "        results = model(batch_files)  # Dự đoán trên batch hiện tại\n",
    "        from IPython.display import clear_output\n",
    "        clear_output()\n",
    "\n",
    "        for result in results:\n",
    "            img_path = result.path\n",
    "            img_name = os.path.basename(img_path)\n",
    "            img_width, img_height = result.orig_img.shape[1], result.orig_img.shape[0]\n",
    "\n",
    "            for box in result.boxes:\n",
    "                xyxy = box.xyxy[0].cpu().numpy()\n",
    "                class_id = int(box.cls[0].item())\n",
    "                confidence = box.conf[0].item()\n",
    "                x_center, y_center, width, height = xyxy_to_xywh(xyxy, img_width, img_height)\n",
    "\n",
    "                # Ghi kết quả vào tệp\n",
    "                f.write(f\"{img_name} {class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f} {confidence:.6f}\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: predict.txt (deflated 71%)\n"
     ]
    }
   ],
   "source": [
    "# Zip file predict.txt for submission\n",
    "!zip -r predict.zip predict.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
